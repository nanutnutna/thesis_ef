{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "synonyms_file = r'C:\\Users\\Nattapot\\Desktop\\thesis_ef\\extract_data\\synonyms.txt'\n",
    "with open(synonyms_file, encoding=\"utf-8\") as f:\n",
    "    synonyms_list = [line.strip().split(\", \") for line in f.readlines()]\n",
    "\n",
    "dataset_file = r'C:\\Users\\Nattapot\\Desktop\\thesis_ef\\evaluate\\emission_factor_20250210.csv'\n",
    "df = pd.read_csv(dataset_file, header=None) \n",
    "df['combined'] = df[[0, 1, 2]].apply(lambda row: \" \".join(str(value) for value in row if pd.notnull(value)), axis=1)\n",
    "\n",
    "results = []\n",
    "for synonyms in synonyms_list:\n",
    "    keyword = synonyms[0] \n",
    "    matched_rows = []\n",
    "    for index, row in df.iterrows():\n",
    "        row_text = row['combined']\n",
    "        if any(word in row_text for word in synonyms):\n",
    "            matched_rows.append(index) \n",
    "\n",
    "    results.append({\"Keyword\": keyword, \"Synonyms\": \", \".join(synonyms), \"Rows Found\": matched_rows})\n",
    "result_df = pd.DataFrame(results)\n",
    "\n",
    "result_df.to_csv(\"ground_truth.csv\",index=False,encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = r'C:\\Users\\Nattapot\\Desktop\\thesis_ef\\evaluate\\ground_truth.csv'\n",
    "df = pd.read_csv(gt) \n",
    "synonym_dict = {row['Keyword']:row['Synonyms'].replace(' ','').split(',') for _,row in df.iterrows()}\n",
    "ground_truth = {row['Keyword']:row['Rows Found'].strip(\"[]\").split(\", \") for _,row in df.iterrows()}\n",
    "# synonym_dict = {\n",
    "#     \"Anthracite\": [\"Anthracite\", \"แอนทราไซต์\", \"ถ่านหินชนิดแข็ง\", \"ถ่านหินคุณภาพสูง\"],\n",
    "#     \"Bagasse\": [\"Bagasse\", \"ชานอ้อย\", \"กากอ้อย\"],\n",
    "#     \"Benzene\": [\"Benzene\", \"เบนซีน\"]\n",
    "# }\n",
    "\n",
    "\n",
    "# ground_truth = {\n",
    "#     \"Anthracite\": [\"1\", \"2\", \"3\"],\n",
    "#     \"Bagasse\": [\"4\", \"5\", \"6\"],\n",
    "#     \"Benzene\": [\"7\", \"8\"]\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import pandas as pd\n",
    "\n",
    "es = Elasticsearch(\"https://localhost:9200\",\n",
    "                   basic_auth=(\"elastic\",\"JODDaUKomoKuPHFM2zEc\"),\n",
    "                   ca_certs=\"C:/Users/Nattapot/Documents/elasticsearch-8.17.0/config/certs/http_ca.crt\"\n",
    ")\n",
    "\n",
    "\n",
    "def search_and_evaluate_synonym(query, synonym_dict, ground_truth, index=\"emission_data_upsert\", size=10):\n",
    "    \"\"\"\n",
    "    ค้นหาใน Elasticsearch พร้อมใช้ Synonym Matching และคำนวณ Precision และ Recall\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not query:\n",
    "            return {\"error\": \"No query provided.\"}\n",
    "\n",
    "        # ขยาย Query ด้วย Synonym Dictionary\n",
    "        expanded_queries = synonym_dict.get(query, [query])  # ใช้คำเดิมถ้าไม่มีใน Dictionary\n",
    "        # สร้าง Query Elasticsearch\n",
    "        response = es.search(index=index, body={\n",
    "            \"query\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": \" \".join(expanded_queries),  # ใช้ Synonyms ทั้งหมดรวมกัน\n",
    "                    \"fields\": [\"ชื่อ^3\", \"รายละเอียด\", \"กลุ่ม\"],\n",
    "                    \"type\": \"best_fields\",\n",
    "                    \"operator\": \"or\"  # ใช้ \"or\" เพื่อให้ตรงกับคำใดคำหนึ่งใน Synonym\n",
    "                }\n",
    "            },\n",
    "            \"size\": size\n",
    "        })\n",
    "\n",
    "\n",
    "        retrieved_ids = [hit[\"_id\"] for hit in response['hits']['hits']]\n",
    "        \n",
    "        relevant_ids = ground_truth.get(query, [])\n",
    "        tp = len(set(retrieved_ids) & set(relevant_ids))  # True Positives\n",
    "        fp = len(set(retrieved_ids) - set(relevant_ids))  # False Positives\n",
    "        fn = len(set(relevant_ids) - set(retrieved_ids))  # False Negatives\n",
    "\n",
    "        # คำนวณ Precision และ Recall\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "        # คำนวณ Average Precision (AP)\n",
    "        num_relevant = 0\n",
    "        precision_at_k = []\n",
    "        \n",
    "        for k, doc_id in enumerate(retrieved_ids, 1):\n",
    "            if doc_id in relevant_ids:\n",
    "                num_relevant += 1\n",
    "                precision_at_k.append(num_relevant / k)\n",
    "        \n",
    "        ap_score = sum(precision_at_k) / len(relevant_ids) if relevant_ids else 0\n",
    "\n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"expanded_queries\": expanded_queries,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"AP\": ap_score,\n",
    "            \"retrieved_ids\": retrieved_ids,\n",
    "            \"relevant_ids\": relevant_ids,\n",
    "            \"true_positives\": tp,\n",
    "            \"false_positives\": fp,\n",
    "            \"false_negatives\": fn,\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "\n",
    "for key in ground_truth.keys():\n",
    "    result = search_and_evaluate_synonym(key, synonym_dict, ground_truth)\n",
    "\n",
    "    results_list.append({\n",
    "        \"Query\": result[\"query\"],\n",
    "        \"Expanded Queries\": \", \".join(result[\"expanded_queries\"]),\n",
    "        \"Precision\": result[\"precision\"],\n",
    "        \"Recall\": result[\"recall\"],\n",
    "        \"AP\": result[\"AP\"],\n",
    "        \"Retrieved IDs\": \", \".join(result[\"retrieved_ids\"]),\n",
    "        \"Relevant IDs\": \", \".join(result[\"relevant_ids\"]),\n",
    "        \"True Positives\": result[\"true_positives\"],\n",
    "        \"False Positives\": result[\"false_positives\"],\n",
    "        \"False Negatives\": result[\"false_negatives\"]\n",
    "    })\n",
    "lst_ap = sum([value['AP'] for value in results_list])\n",
    "map_score = lst_ap/len(results_list)\n",
    "\n",
    "df_results = pd.DataFrame(results_list)\n",
    "df_results['MAP'] = map_score\n",
    "df_results.to_csv(\"evaluation_results.csv\", index=False, encoding='utf-8-sig')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
